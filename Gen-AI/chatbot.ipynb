{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "895f3d7c",
   "metadata": {},
   "source": [
    "## Building A Chatbot\n",
    "In this video We'll go over an example of how to design and implement an LLM-powered chatbot. This chatbot will be able to have a conversation and remember previous interactions.\n",
    "\n",
    "Note that this chatbot that we build will only use the language model to have a conversation. There are several other related concepts that you may be looking for:\n",
    "\n",
    "- Conversational RAG: Enable a chatbot experience over an external source of data\n",
    "- Agents: Build a chatbot that can take actions\n",
    "\n",
    "This video tutorial will cover the basics which will be helpful for those two more advanced topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c0d2a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dda9998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c66a2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "model = ChatGroq(model=\"llama3-70b-8192\", groq_api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c8b3647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Namaste Gajalakshmi! It's wonderful to meet you! As an AI Engineer, you must be working on some fascinating projects. What kind of AI applications or technologies are you currently focused on? Are you working on natural language processing, computer vision, or something else?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 26, 'total_tokens': 85, 'completion_time': 0.182280852, 'prompt_time': 0.005399386, 'queue_time': 0.715973309, 'total_time': 0.187680238}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None}, id='run--8235a2c7-b680-4c03-a84d-57f5b3cd608d-0', usage_metadata={'input_tokens': 26, 'output_tokens': 59, 'total_tokens': 85})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, my name is Gajalakshmi I am a AI Engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc81ab5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"?\\n\\nYou told me earlier that your name is Gajalakshmi and you're an AI Engineer!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 94, 'total_tokens': 117, 'completion_time': 0.068817947, 'prompt_time': 0.011666821, 'queue_time': 0.322399708, 'total_time': 0.080484768}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None}, id='run--fe053fff-95f9-4527-94ea-d55f3c0ecff3-0', usage_metadata={'input_tokens': 94, 'output_tokens': 23, 'total_tokens': 117})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, my name is Gajalakshmi I am a AI Engineer\"),\n",
    "        AIMessage(content=\"Namaste Gajalakshmi! It's great to meet you, a talented AI Engineer! What an exciting field you're in! Are you working on any specific projects or applications of AI that you'd like to share about?\"),\n",
    "        AIMessage(content=\"Hey what's my name and what do i do\")     \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9abb39",
   "metadata": {},
   "source": [
    "Message History we can use a class to wrap our model and make it stateful will keep track the model of input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5de5f3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad24d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3fe9fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, my name is Gajalakshmi I am a AI Engineer\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49a502f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Namaste Gajalakshmi! It's great to meet you! As an AI Engineer, you must be working on some exciting projects that involve building intelligent systems that can think and learn like humans. What specific areas of AI engineering interest you the most? Are you working on natural language processing, computer vision, or perhaps reinforcement learning?\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3126748b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Gajalakshmi!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 109, 'total_tokens': 120, 'completion_time': 0.032605133, 'prompt_time': 0.01894414, 'queue_time': 0.249522709, 'total_time': 0.051549273}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None}, id='run--75f293b6-c45a-492d-9670-3e4f5e158445-0', usage_metadata={'input_tokens': 109, 'output_tokens': 11, 'total_tokens': 120})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9af93aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't know your name. I'm a large language model, I don't have the ability to know personal information about you, including your name. Each time you interact with me, it's a new conversation and I don't retain any information from previous conversations. If you'd like to tell me your name, I'd be happy to chat with you!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the config -->session id\n",
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what's my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fcebff",
   "metadata": {},
   "source": [
    "Prompt template helps to turn raw user information into a format that the llm can work with In this case the raw user input is just a message which we are passing to the llm let's now make a bit more complicated first let's add in a system message with custom message with custom instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d464a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\",\"you are an helpful assitant. Answer all the questions to the nest of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "364cd0ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Namaste Gajalakshmi! It's nice to meet you. That's a beautiful name you have, by the way. Gajalakshmi is a name that symbolizes prosperity and good fortune. It's also associated with the goddess of wealth and good luck in Hindu mythology.\\n\\nHow can I assist you today, Gajalakshmi? Do you have any questions or topics you'd like to discuss? I'm all ears!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 94, 'prompt_tokens': 42, 'total_tokens': 136, 'completion_time': 0.284462791, 'prompt_time': 0.006270074, 'queue_time': 1.899584133, 'total_time': 0.290732865}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None}, id='run--6f53bc8f-e4aa-4ef3-bdd4-e0d0178e6ff5-0', usage_metadata={'input_tokens': 42, 'output_tokens': 94, 'total_tokens': 136})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Gajalakshmi\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf07de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7d4e5ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Namaste Gajalakshmi! It's a pleasure to meet you. I'm your helpful assistant, here to provide you with assistance and answer any questions you may have. What can I help you with today?\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi My name is Gajalakshmi\")],\n",
    "    config = config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85160eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I remember! Your name is Gajalakshmi.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6230492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add more complexity\n",
    "prompt= ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"you are an helpful assitant Answer all the question to the best of ability in {language}.\",\n",
    "\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "chain= prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7682620f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Namaste Gajalakshmi ji! मैं आपकी मदद के लिए तैयार हूँ। क्या आप कोई प्रश्न पूछना चाहती हैं या कोई विषय पर चर्चा करना चाहती हैं?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"My name is Gajalakshmi\")],\"language\":\"Hindi\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2347bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Namaste Gajalakshmi ji! मैं आपकी मदद के लिए तैयार हूँ। क्या आप कोई प्रश्न पूछना चाहती हैं या कोई विषय पर चर्चा करना चाहती हैं?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 42, 'total_tokens': 104, 'completion_time': 0.192330054, 'prompt_time': 0.005358667, 'queue_time': 0.564630263, 'total_time': 0.197688721}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None}, id='run--5ba676a3-3c7f-4a87-9ab3-d805d32356a0-0', usage_metadata={'input_tokens': 42, 'output_tokens': 62, 'total_tokens': 104})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da3fd6f",
   "metadata": {},
   "source": [
    "we need to save correct key to use to save the chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "549a96d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "759c5e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'नमस्ते गजलक्ष्मी जी! मैं आपका सहायक हूँ। मैं आपके सभी प्रश्नों का उत्तर देने के लिए यहाँ हूँ। क्या मैं आपकी कोई मदद कर सकता हूँ?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {'messages':[HumanMessage(content=\"Hi, I am Gajalakshmi\")],\"language\":\"Hindi\"},\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7e7aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"what my name\")],\"language\":\"Hindi\"},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f21eef53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'आपका नाम गजलक्ष्मी है!'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2533bf",
   "metadata": {},
   "source": [
    "Managing the conservasation history\n",
    "one important concept to understand when building the chatbot is how to manage conversational history.if left unmanaged the list of messages the list of message will grow unbounded and potentially overflow the context window of the llm. therefore important step to add a that limits the size of the message you are passing on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4a7a92",
   "metadata": {},
   "source": [
    "trim message helps to reduce how many messages we are sending to the model. the trimmer allows us to speciy how many tokens we wnat to keep along with parameters like if we want to always keep the system message and whether allow partial messsages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "166eee8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gajalakshmi G\\Documents\\Gen-AI\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7179316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm not sure! I don't have any information about your personal preferences. But I can ask, what's your favorite ice cream flavor?\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    "    \n",
    ")\n",
    "\n",
    "response=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"What ice cream do i like\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95a5a45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked \"what\\'s 2 + 2\"'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4020deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets wrap this in the MEssage History\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "config={\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40d5c779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I don't know your name! You didn't tell me earlier, and I don't have any information about you. If you want to share your name, I'd be happy to know!\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"whats my name?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd73dbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You didn't ask a math problem yet. This is the beginning of our conversation. If you'd like to ask a math problem, I'm here to help!\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": [HumanMessage(content=\"what math problem did i ask?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
